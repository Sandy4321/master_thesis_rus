\chapter{Существующий подход}
\indent Большинство методик классификации СПО матриц можно разделить на две группы:
\begin{enumerate}
    \item Ядерные методы, основанные на высчитаной заранее матрице расстояний между СПО матрицами
    \item Двухшаговые алгоритмы, состоящие из (1) проекции всех СПО матриц на подходящее касательное пространство и (2) классификации получившихся векторов линейными алгоритмами классификации (такими как логистическая регрессия или линейный диксриминантный анализ)
\end{enumerate}

\section{Ядерные методы}
\indent Ядерные методы в $\setR^n$ крайне эффективны в задачах машинного обучения и компьютерного зрения, требующих распознавания нелинейных структур в данных. Поэтому ядерные методы являются достаточно распространенным подходом к классификации коннектомов, так как они могут обрабатывать коннектомы как графы, тогда как другие методы обычно требуют конвертации коннектомов в векторы (например, векторы глобальной метрики на графах). Основная идея ядерных методов состоит в том, чтобы отразить данные в пространство большей размерности. В случае данной работы это отображение является построением матрицы расстояний между коннектомами, на основе введенного расстояния или подобного расстоянию измерения между коннектомами. Например, расстояние, основанное на сходстве разбиения структурных коннектомов на группы было представлено в \cite{kurmukov2016classification}.\\
\indent Методы, работающие с римановым многообразием, используют метрику на $\manM$. Когда выбрано расстояние $\delta_{spd}(\bs_i, \bs_j)$, алгоритм классификации не вызывает затруднений. 
\subsection{Положительно определенные ядра на многообразиях}
\indent В $\setR^n$ гауссовское ядро может быть выражено следующим образом с использованием евклидова расстояние между точками $x_i, x_j$:
$$ K(x_i, x_j) = exp\Big(\frac{||x_i - x_j||^2}{2\sigma^2}\Big) $$
Чтобы определить ядро на римановом многообразии, нужно заменить евклидово расстояние на более точное геодезическое расстояние на многообразии. Однако не все геодезические позволяют построить положительно определенное ядро. \\
\indent Начнем с определения положительно и отрицательно определенных ядер \cite{berg1984harmonic}
\begin{definition}
Пусть ${\mathcal X}$ – непустое множество. Функция $f: ({\mathcal X} \times {\mathcal X}) \Rightarrow \setR$ называется положительно (отрицательно) определенным ядром тогда и только тогда, когда $f$ симметрична и $$ \sum_{\substack{i,j}}^m c_ic_jf(x_i, x_j) \geq 0 (\leq 0) $$
для любого $m \in \setN, \set{x_1, \ldots, x_m} \subset \manX, \set{c_1, \ldots, c_m} \subset \setR$, причем для отрицательно определенного ядра $\sum_{i=1}^m c_i=0$
\end{definition}
\begin{theorem}
Пусть $(\manM, g)$ - метрическое пространство и определим отображение $K:(\manM \times \manM) \Rightarrow \setR$ следующим образом:
$$ K(x_i, x_j) = exp\Big(\frac{-d^2(x_i, x_j)}{2\sigma^2}\Big) $$
В таком случае $K$ является положительно определенным ядром для любых $\sigma>0$ тогда и только тогда, когда существует линейное пространство $\Nu$ с заданным на нем скалярным произведением и функция $\psi: \manM \Rightarrow \Nu$ такая, что $d(x_i, x_j)=\norm{\psi(x_i) - \psi(x_j)}_{\Nu}$
\end{theorem}
Доказательство этой теоремы рассмотрено в \cite{jayasumana2013kernel}
Следующая теорема была введена в \cite{schoenberg1938metric}
\begin{theorem}\label{schoenberg}
Пусть $\manX$ - непустое множество и $f: (\manX \times \manX) \Rightarrow \setR$ - функция. Ядро $exp(-\gamma f(x_i,x_j))$ положительно определено для любых $t>0$ тогда и только тогда, когда $f$ отрицательно определена.
\end{theorem}
Детальное доказательство теоремы \eqref{schoenberg} можно найти в главе 3, теорема 2.2 в работе \cite{berg1984harmonic}.

\indent Мы можем построить ядро следующим образом:
\begin{equation}\label{kernel}
    K_{spd} = exp(-\gamma \delta_{spd}(\bs_i, \bs_j),
\end{equation}

где $\gamma>0$ - параметр. Поскольку $\delta_{spd}$ является метрикой, ядро $K_P$ положительно определено. Таким образом, можем использовать алгоритм машины опорных векторов \cite{scholkopf2001learning} для классификации на основе $K_{spd}$ 

\section{Классификация в касательном пространстве}
 \indent Многие эффективные алгоритмы (например, LDA, SVM) основаны на основаны на проекции данных на гиперплоскости. Соответственно, они не могут быть реализованы напрямую на римановом многообразии. Реализация более простых алгоритмов может осуществляться с использованием пространства $T_\bc \manM$, касательного к рассматриваемому многообразию.  \\
\indent Принципиальный вопрос в этом подходе заключается в выборе опорной точки $\bs$, которая должна находиться достаточно близко к точкам обучающего множества $\set{\bs_i, y_i}_{i=1}^n$. Стандартным вариантом опорной точки является геометрическое среднее всех матриц, которое задается следующим образом:
 $$ \bs_m = Mean(\bs_1, \ldots, \bs_n) = arg \min_{\substack{\bs \in S(n)}}\sum_{\substack{i=1}}^n \delta_{spd}^2(\bs, \bs_i) $$
 \indent Это среднее также называется геодезическим средним. Каждая ковариационная матрица затем проецируется на касательное пространство, формируя $m$-мерные векторы, где $m=\frac{n(n+1)}{2}$:
 $$ \bc_i = upper(\bs_m^{-\frac{1}{2}}Log_{\bs_m}(\bs_i)\bs_m^{-\frac{1}{2}}) $$
 \indent Эффективный алгоритм вычисления среднего для множества СПО матриц был представлен в \cite{barachant2013classification} \\
 \indent Таким образом мы переходим из нелинейного пространства, в котором невозможно использовать евклидово расстояние, в линейное с помощью заведомо линейного преобразования - проекции.
